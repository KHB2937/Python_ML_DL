{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zihvvan/DeepLearning/blob/main/zihvvan/ch09_DL_09_cGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cGAN으로 원하는 이미지 생성"
      ],
      "metadata": {
        "id": "xK9xZ18zQhZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JOBDl2HBQdUa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 패러미터\n",
        "EPOCHS = 300\n",
        "BATCH_SIZE = 100\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else 'cpu')\n",
        "print(f'사용하고 있는 디바이스 : {DEVICE}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_21RoYYRo7x",
        "outputId": "dd01e620-6fad-473a-fe76-530ab7410f98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용하고 있는 디바이스 : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 로딩\n",
        "# Fashoin MNIST 데이터셋\n",
        "trainset = datasets.FashionMNIST(\n",
        "    './.data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = trainset,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "id": "Ov8dAhjCRxKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6a9be59-ccfb-4f6a-8778-a8a8064e2e59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./.data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 15997159.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./.data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./.data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./.data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 270436.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./.data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./.data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./.data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5085108.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./.data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./.data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./.data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 20564073.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./.data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./.data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성자 (Generator)\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(110, 256), # tensor 100개 input -> 110개 -> 100개 + 10개의 라벨을 합쳐줘서 학습\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1024), # 한 층 더 늚 (이전 예제에 비해)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 784),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        # cGAN에서는 왜 nn.LeakyReLU(0.2, inplace=True) 같이 inplace를 True로 구현하나요? -> 그냥 속도 때문에.\n",
        "\n",
        "        self.embed = nn.Embedding(10, 10) # n x 1 -> n x 10 연속적으로 곱하기\n",
        "        # 연속된 임베딩을 층을 만들어줘야 학습에 유리\n",
        "    \n",
        "    def forward(self, z, labels): # 가짜 이미지가 될 확률분포 텐서 z\n",
        "        c = self.embed(labels) # 정답값 층을 임베딩한(연속적으로 확장시킨) c\n",
        "        x = torch.cat([z, c], 1) # 라벨과 z를 이어붙임 (무작위 벡터, 클래스 레이블)\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "ESZzYytpR0MR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cGAN 생성자](https://github.com/BigData23th/Data/raw/main/dl_05_04.png)\n",
        "> cGAN 생성자"
      ],
      "metadata": {
        "id": "3HJdzpVqTxYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 판별자도 레이블 정보를 입력 받음\n",
        "# -> 생성자에서 이미지를 만들 때 쓴 레이블 정보를 입력 받아서\n",
        "# \"레이블이 주어졌을 때 가짜인 확률과 진짜인 확률\"을 추정\n",
        "# 판별자 (Discriminator)\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(10, 10)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28 * 28 + 10, 1024), # 794, 1024\n",
        "            # 레이블 정보를 전달하기 위해 이미지 크기 (28*28 = 784)에 10을 더해줌\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3), # 성능 개선용 드롭아웃\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3), # 성능 개선용 드롭아웃\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3), # 성능 개선용 드롭아웃\n",
        "            nn.Linear(256, 1), # 진짜인지 가짜인지 1로 (이진분류)\n",
        "            nn.Sigmoid() # 0~1.\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, labels):\n",
        "        c = self.embed(labels)\n",
        "        x = torch.cat([x, c], 1)\n",
        "        return self.model(x) # 진짜인지 가짜인지 (0, 1)"
      ],
      "metadata": {
        "id": "Q3RyKWC5ULFk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cGAN 판별자](https://github.com/BigData23th/Data/raw/main/dl_05_05.png)\n",
        "> cGAN 판별자"
      ],
      "metadata": {
        "id": "8bfrm2BmVuIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 인스턴스 생성\n",
        "D = Discriminator().to(DEVICE)\n",
        "G = Generator().to(DEVICE)\n",
        "\n",
        "# 오차함수 & 최적화함수\n",
        "criterion = nn.BCELoss() # 이진 크로스 엔트로피 (Binary Cross Entropy) 오차함수\n",
        "d_optimizer = optim.Adam(D.parameters(), lr=0.0002)\n",
        "g_optimizer = optim.Adam(G.parameters(), lr=0.0002)"
      ],
      "metadata": {
        "id": "ySqGmjF-UP6B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)\n",
        "for epoch in range(EPOCHS):\n",
        "    # i: 100개인데, 배치 사이즈가 10이면? [0, 1, 2, 3... 9]\n",
        "    # (data, label) -> 이미지, 이미지의 분류\n",
        "    # ---\n",
        "    # for i, (images, _) in enumerate(train_loader): # DataLoader는 BatchSize만큼 끊어서 데이터를 제공\n",
        "    for i, (images, labels) in enumerate(train_loader): # cGAN에서는 라벨이 중요\n",
        "        # BATCH_SIZE, 1, 28, 28 -> BATCH_SIZE, 784\n",
        "        images = images.reshape(BATCH_SIZE, -1).to(DEVICE) # 진짜 이미지\n",
        "\n",
        "        # '진짜'와 '가짜' 레이블 생성\n",
        "        real_labels = torch.ones(BATCH_SIZE, 1).to(DEVICE) # 1로 채워진 텐서\n",
        "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE) # 0로 채워진 텐서\n",
        "\n",
        "        # 판별자가 진짜 이미지를 진짜로 인식하는 오차 계산\n",
        "        labels = labels.to(DEVICE)\n",
        "        outputs = D(images, labels) # 판별자가 진짜 이미지 + 라벨값을 0~1으로 진짜/가짜 여부를 판단\n",
        "        d_loss_real = criterion(outputs, real_labels) # BCELoss\n",
        "        real_score = outputs # 판별자 vs 진짜 이미지\n",
        "\n",
        "        # 무작위 텐서로 가짜 이미지 생성\n",
        "        z = torch.randn(BATCH_SIZE, 100).to(DEVICE) # 정규분포를 따르는 100개의 특성을 가진 가짜 이미지 텐서\n",
        "        g_label = torch.randint(0, 10, (BATCH_SIZE,)).to(DEVICE) # 가짜 이미지의 가짜 답(랜덤으로 만들어진)\n",
        "        # 정규분포로부터 생성된 무작위 텐서를 (생성자 모델이) 입력받아서 실제 이미지와 차원(모양)이 같은 텐서를 생성\n",
        "        fake_images = G(z, g_label)\n",
        "\n",
        "        # 판별자가 가짜 이미지를 가짜로 인식하는 오차를 계산\n",
        "        outputs = D(fake_images, g_label)\n",
        "        # 판별자가 맞추었는가?\n",
        "        d_loss_fake = criterion(outputs, fake_labels) # 오차\n",
        "        fake_score = outputs # 판별자 vs 가짜 이미지\n",
        "\n",
        "        # 진짜와 가짜 이미지를 가지고 낸 오차\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "        # 역전파 알고리즘 판별자 모델의 학습을 진행\n",
        "        d_optimizer.zero_grad()\n",
        "        g_optimizer.zero_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step() # 판별자의 패러미터 개선\n",
        "\n",
        "        # 생성자가 판별자를 속였는지에 대해 (생성자 성능) 오차를 계산\n",
        "        fake_images = G(z, g_label)\n",
        "        outputs = D(fake_images, g_label)\n",
        "        # 생성자가 속였는가?\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "\n",
        "        # 역전파 알고리즘으로 생성자 모델의 학습을 진행\n",
        "        d_optimizer.zero_grad()\n",
        "        g_optimizer.zero_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step() # 생성자의 패러미터 개선\n",
        "    # ---\n",
        "    # 학습 진행도 체크 로그\n",
        "    # 판별자가 진짜를 알아본 정확도 D(x)와 가짜를 진짜로 인식한 정확도 D(G(z))\n",
        "    print('Epoch [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
        "          .format(epoch, EPOCHS, d_loss.item(), g_loss.item(), \n",
        "                  real_score.mean().item(), fake_score.mean().item()))"
      ],
      "metadata": {
        "id": "6GbL0d73ce60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "c9510569-d8e7-426c-b33c-7e1210e8cc82"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/300], d_loss: 0.4009, g_loss: 6.7502, D(x): 0.88, D(G(z)): 0.12\n",
            "Epoch [1/300], d_loss: 0.4824, g_loss: 3.7046, D(x): 0.83, D(G(z)): 0.12\n",
            "Epoch [2/300], d_loss: 0.5091, g_loss: 5.4351, D(x): 0.81, D(G(z)): 0.10\n",
            "Epoch [3/300], d_loss: 0.4046, g_loss: 4.9434, D(x): 0.89, D(G(z)): 0.13\n",
            "Epoch [4/300], d_loss: 0.9256, g_loss: 2.6979, D(x): 0.82, D(G(z)): 0.26\n",
            "Epoch [5/300], d_loss: 0.5188, g_loss: 2.7816, D(x): 0.86, D(G(z)): 0.20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b0600022b2c2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# for i, (images, _) in enumerate(train_loader): # DataLoader는 BatchSize만큼 끊어서 데이터를 제공\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# cGAN에서는 라벨이 중요\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m# BATCH_SIZE, 1, 28, 28 -> BATCH_SIZE, 784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 진짜 이미지\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = {\n",
        "    0: 'T-shirt/top',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'Ankle boot'\n",
        "}"
      ],
      "metadata": {
        "id": "TFuEL5nUdtDw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/BigData23th/Data/raw/main/d2.pt\n",
        "!wget https://github.com/BigData23th/Data/raw/main/g2.pt"
      ],
      "metadata": {
        "id": "oFYU6xWOd54E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c978ade-7e36-409d-c5f5-e0068288bbf4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-04 07:32:22--  https://github.com/BigData23th/Data/raw/main/d2.pt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BigData23th/Data/main/d2.pt [following]\n",
            "--2023-04-04 07:32:23--  https://raw.githubusercontent.com/BigData23th/Data/main/d2.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5884948 (5.6M) [application/octet-stream]\n",
            "Saving to: ‘d2.pt’\n",
            "\n",
            "d2.pt               100%[===================>]   5.61M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-04-04 07:32:23 (75.5 MB/s) - ‘d2.pt’ saved [5884948/5884948]\n",
            "\n",
            "--2023-04-04 07:32:23--  https://github.com/BigData23th/Data/raw/main/g2.pt\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BigData23th/Data/main/g2.pt [following]\n",
            "--2023-04-04 07:32:23--  https://raw.githubusercontent.com/BigData23th/Data/main/g2.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5958676 (5.7M) [application/octet-stream]\n",
            "Saving to: ‘g2.pt’\n",
            "\n",
            "g2.pt               100%[===================>]   5.68M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-04-04 07:32:23 (71.0 MB/s) - ‘g2.pt’ saved [5958676/5958676]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D.load_state_dict(torch.load('d2.pt'))\n",
        "G.load_state_dict(torch.load('g2.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8c2b5F5eDXr",
        "outputId": "80bcfc84-4a97-4827-ca15-443757714163"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 만들고 싶은 아이템 생성하고 시각화하기\n",
        "# 아이템 번호\n",
        "item_number = 9 #@param {\"type\":\"number\"}\n",
        "z = torch.randn(1, 100).to(DEVICE) # 배치 크기 1\n",
        "g_label = torch.full((1,), item_number, dtype=torch.long).to(DEVICE)\n",
        "sample_images = G(z, g_label) # 텐서\n",
        "# CPU, Numpy -> Matplotlib\n",
        "sample_images_img = np.reshape(sample_images.data.cpu().numpy()\n",
        "                               [0],(28, 28)) # 784\n",
        "plt.title(CLASSES[item_number])\n",
        "plt.imshow(sample_images_img, cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "FcZYXkMNLo4-",
        "outputId": "d4a0ff12-ef6f-4b6f-8658-43a94ad1a9c3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> PyTorch를 통해서 GAN 모델을 사용한다고 했을 때, 가장 최신 GAN 모델은 뭐야? + BingGPT\n",
        "* https://shareg.pt/3lWApU7"
      ],
      "metadata": {
        "id": "igOsgknANk8T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> https://www.kaggle.com/search?q=dcgan+pytorch+sortBy%3Adate"
      ],
      "metadata": {
        "id": "DmAY3xMpNl0r"
      }
    }
  ]
}