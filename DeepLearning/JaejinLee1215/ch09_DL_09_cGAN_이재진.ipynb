{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaejinLee1215/DeepLearning/blob/main/JaejinLee1215/ch09_DL_09_cGAN_%EC%9D%B4%EC%9E%AC%EC%A7%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cGAN으로 원하는 이미지 생성"
      ],
      "metadata": {
        "id": "xK9xZ18zQhZz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JOBDl2HBQdUa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.utils import save_image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼 패러미터\n",
        "EPOCHS = 300\n",
        "BATCH_SIZE = 100\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else 'cpu')\n",
        "print(f'사용하고 있는 디바이스 : {DEVICE}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_21RoYYRo7x",
        "outputId": "39619786-b8fd-471f-d9d3-5d66bdde6956"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용하고 있는 디바이스 : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 로딩\n",
        "# Fashoin MNIST 데이터셋\n",
        "trainset = datasets.FashionMNIST(\n",
        "    './.data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        ")\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset = trainset,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "id": "Ov8dAhjCRxKY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dea2a2a-cf3e-44e2-d243-f6183570f94e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./.data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:03<00:00, 8571916.52it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./.data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./.data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./.data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 144294.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./.data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./.data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./.data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 2728885.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./.data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./.data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./.data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 19864100.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./.data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./.data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 생성자 (Generator)\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(110, 256), # tensor 100개 input -> 110개 -> 100개 + 10개의 라벨을 합쳐줘서 학습\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 1024), # 한 층 더 늚 (이전 예제에 비해)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(1024, 784),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        # cGAN에서는 왜 nn.LeakyReLU(0.2, inplace=True) 같이 inplace를 True로 구현하나요? -> 그냥 속도 때문에.\n",
        "\n",
        "        self.embed = nn.Embedding(10, 10) # n x 1 -> n x 10 연속적으로 곱하기\n",
        "        # 연속된 임베딩을 층을 만들어줘야 학습에 유리\n",
        "    \n",
        "    def forward(self, z, labels): # 가짜 이미지가 될 확률분포 텐서 z\n",
        "        c = self.embed(labels) # 정답값 층을 임베딩한(연속적으로 확장시킨) c\n",
        "        x = torch.cat([z, c], 1) # 라벨과 z를 이어붙임 (무작위 벡터, 클래스 레이블)\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "ESZzYytpR0MR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cGAN 생성자](https://github.com/BigData23th/Data/raw/main/dl_05_04.png)\n",
        "> cGAN 생성자"
      ],
      "metadata": {
        "id": "3HJdzpVqTxYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 판별자도 레이블 정보를 입력 받음\n",
        "# -> 생성자에서 이미지를 만들 때 쓴 레이블 정보를 입력 받아서\n",
        "# \"레이블이 주어졌을 때 가짜인 확률과 진짜인 확률\"을 추정\n",
        "# 판별자 (Discriminator)\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed = nn.Embedding(10, 10)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(28 * 28 + 10, 1024), # 794, 1024\n",
        "            # 레이블 정보를 전달하기 위해 이미지 크기 (28*28 = 784)에 10을 더해줌\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3), # 성능 개선용 드롭아웃\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3), # 성능 개선용 드롭아웃\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(0.3), # 성능 개선용 드롭아웃\n",
        "            nn.Linear(256, 1), # 진짜인지 가짜인지 1로 (이진분류)\n",
        "            nn.Sigmoid() # 0~1.\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, labels):\n",
        "        c = self.embed(labels)\n",
        "        x = torch.cat([x, c], 1)\n",
        "        return self.model(x) # 진짜인지 가짜인지 (0, 1)"
      ],
      "metadata": {
        "id": "Q3RyKWC5ULFk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![cGAN 판별자](https://github.com/BigData23th/Data/raw/main/dl_05_05.png)\n",
        "> cGAN 판별자"
      ],
      "metadata": {
        "id": "8bfrm2BmVuIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 인스턴스 생성\n",
        "D = Discriminator().to(DEVICE)\n",
        "G = Generator().to(DEVICE)\n",
        "\n",
        "# 오차함수 & 최적화함수\n",
        "criterion = nn.BCELoss() # 이진 크로스 엔트로피 (Binary Cross Entropy) 오차함수\n",
        "d_optimizer = optim.Adam(D.parameters(), lr=0.0002)\n",
        "g_optimizer = optim.Adam(G.parameters(), lr=0.0002)"
      ],
      "metadata": {
        "id": "ySqGmjF-UP6B"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)\n",
        "for epoch in range(EPOCHS):\n",
        "    # i: 100개인데, 배치 사이즈가 10이면? [0, 1, 2, 3... 9]\n",
        "    # (data, label) -> 이미지, 이미지의 분류\n",
        "    # ---\n",
        "    # for i, (images, _) in enumerate(train_loader): # DataLoader는 BatchSize만큼 끊어서 데이터를 제공\n",
        "    for i, (images, labels) in enumerate(train_loader): # cGAN에서는 라벨이 중요\n",
        "        # BATCH_SIZE, 1, 28, 28 -> BATCH_SIZE, 784\n",
        "        images = images.reshape(BATCH_SIZE, -1).to(DEVICE) # 진짜 이미지\n",
        "\n",
        "        # '진짜'와 '가짜' 레이블 생성\n",
        "        real_labels = torch.ones(BATCH_SIZE, 1).to(DEVICE) # 1로 채워진 텐서\n",
        "        fake_labels = torch.zeros(BATCH_SIZE, 1).to(DEVICE) # 0로 채워진 텐서\n",
        "\n",
        "        # 판별자가 진짜 이미지를 진짜로 인식하는 오차 계산\n",
        "        labels = labels.to(DEVICE)\n",
        "        outputs = D(images, labels) # 판별자가 진짜 이미지 + 라벨값을 0~1으로 진짜/가짜 여부를 판단\n",
        "        d_loss_real = criterion(outputs, real_labels) # BCELoss\n",
        "        real_score = outputs # 판별자 vs 진짜 이미지\n",
        "\n",
        "        # 무작위 텐서로 가짜 이미지 생성\n",
        "        z = torch.randn(BATCH_SIZE, 100).to(DEVICE) # 정규분포를 따르는 100개의 특성을 가진 가짜 이미지 텐서\n",
        "        g_label = torch.randint(0, 10, (BATCH_SIZE,)).to(DEVICE) # 가짜 이미지의 가짜 답(랜덤으로 만들어진)\n",
        "        # 정규분포로부터 생성된 무작위 텐서를 (생성자 모델이) 입력받아서 실제 이미지와 차원(모양)이 같은 텐서를 생성\n",
        "        fake_images = G(z, g_label)\n",
        "\n",
        "        # 판별자가 가짜 이미지를 가짜로 인식하는 오차를 계산\n",
        "        outputs = D(fake_images, g_label)\n",
        "        # 판별자가 맞추었는가?\n",
        "        d_loss_fake = criterion(outputs, fake_labels) # 오차\n",
        "        fake_score = outputs # 판별자 vs 가짜 이미지\n",
        "\n",
        "        # 진짜와 가짜 이미지를 가지고 낸 오차\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "        # 역전파 알고리즘 판별자 모델의 학습을 진행\n",
        "        d_optimizer.zero_grad()\n",
        "        g_optimizer.zero_grad()\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step() # 판별자의 패러미터 개선\n",
        "\n",
        "        # 생성자가 판별자를 속였는지에 대해 (생성자 성능) 오차를 계산\n",
        "        fake_images = G(z, g_label)\n",
        "        outputs = D(fake_images, g_label)\n",
        "        # 생성자가 속였는가?\n",
        "        g_loss = criterion(outputs, real_labels)\n",
        "\n",
        "        # 역전파 알고리즘으로 생성자 모델의 학습을 진행\n",
        "        d_optimizer.zero_grad()\n",
        "        g_optimizer.zero_grad()\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step() # 생성자의 패러미터 개선\n",
        "    # ---\n",
        "    # 학습 진행도 체크 로그\n",
        "    # 판별자가 진짜를 알아본 정확도 D(x)와 가짜를 진짜로 인식한 정확도 D(G(z))\n",
        "    print('Epoch [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
        "          .format(epoch, EPOCHS, d_loss.item(), g_loss.item(), \n",
        "                  real_score.mean().item(), fake_score.mean().item()))"
      ],
      "metadata": {
        "id": "6GbL0d73ce60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "daadb0e2-242e-4e7f-a0ef-0dd157aeaa15"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/300], d_loss: 0.6185, g_loss: 4.3171, D(x): 0.86, D(G(z)): 0.06\n",
            "Epoch [1/300], d_loss: 0.2683, g_loss: 5.3650, D(x): 0.93, D(G(z)): 0.11\n",
            "Epoch [2/300], d_loss: 0.1987, g_loss: 4.4420, D(x): 0.93, D(G(z)): 0.08\n",
            "Epoch [3/300], d_loss: 0.2216, g_loss: 4.1630, D(x): 0.93, D(G(z)): 0.06\n",
            "Epoch [4/300], d_loss: 0.6130, g_loss: 2.8853, D(x): 0.86, D(G(z)): 0.20\n",
            "Epoch [5/300], d_loss: 0.5236, g_loss: 2.9969, D(x): 0.88, D(G(z)): 0.20\n",
            "Epoch [6/300], d_loss: 0.7706, g_loss: 2.0479, D(x): 0.74, D(G(z)): 0.22\n",
            "Epoch [7/300], d_loss: 0.6036, g_loss: 2.2064, D(x): 0.72, D(G(z)): 0.15\n",
            "Epoch [8/300], d_loss: 0.6609, g_loss: 2.0482, D(x): 0.77, D(G(z)): 0.20\n",
            "Epoch [9/300], d_loss: 1.1300, g_loss: 2.0171, D(x): 0.67, D(G(z)): 0.28\n",
            "Epoch [10/300], d_loss: 0.7694, g_loss: 1.8605, D(x): 0.72, D(G(z)): 0.20\n",
            "Epoch [11/300], d_loss: 1.0642, g_loss: 1.5719, D(x): 0.59, D(G(z)): 0.24\n",
            "Epoch [12/300], d_loss: 0.8228, g_loss: 1.7933, D(x): 0.72, D(G(z)): 0.24\n",
            "Epoch [13/300], d_loss: 0.9877, g_loss: 1.4619, D(x): 0.72, D(G(z)): 0.37\n",
            "Epoch [14/300], d_loss: 0.8369, g_loss: 1.5412, D(x): 0.72, D(G(z)): 0.27\n",
            "Epoch [15/300], d_loss: 0.9649, g_loss: 1.6749, D(x): 0.69, D(G(z)): 0.30\n",
            "Epoch [16/300], d_loss: 0.9688, g_loss: 1.5281, D(x): 0.68, D(G(z)): 0.31\n",
            "Epoch [17/300], d_loss: 1.1629, g_loss: 1.3035, D(x): 0.65, D(G(z)): 0.33\n",
            "Epoch [18/300], d_loss: 0.7486, g_loss: 1.7726, D(x): 0.73, D(G(z)): 0.24\n",
            "Epoch [19/300], d_loss: 0.8603, g_loss: 1.4702, D(x): 0.70, D(G(z)): 0.29\n",
            "Epoch [20/300], d_loss: 0.8951, g_loss: 1.6906, D(x): 0.68, D(G(z)): 0.27\n",
            "Epoch [21/300], d_loss: 1.1243, g_loss: 1.4220, D(x): 0.57, D(G(z)): 0.29\n",
            "Epoch [22/300], d_loss: 1.0737, g_loss: 1.3817, D(x): 0.62, D(G(z)): 0.32\n",
            "Epoch [23/300], d_loss: 0.9903, g_loss: 1.2869, D(x): 0.68, D(G(z)): 0.35\n",
            "Epoch [24/300], d_loss: 1.0044, g_loss: 1.3739, D(x): 0.66, D(G(z)): 0.34\n",
            "Epoch [25/300], d_loss: 1.0500, g_loss: 1.5145, D(x): 0.70, D(G(z)): 0.39\n",
            "Epoch [26/300], d_loss: 1.1694, g_loss: 1.1003, D(x): 0.60, D(G(z)): 0.40\n",
            "Epoch [27/300], d_loss: 0.9975, g_loss: 1.2466, D(x): 0.66, D(G(z)): 0.34\n",
            "Epoch [28/300], d_loss: 1.1117, g_loss: 1.2407, D(x): 0.65, D(G(z)): 0.36\n",
            "Epoch [29/300], d_loss: 1.0066, g_loss: 1.2558, D(x): 0.66, D(G(z)): 0.37\n",
            "Epoch [30/300], d_loss: 1.1514, g_loss: 1.1663, D(x): 0.58, D(G(z)): 0.37\n",
            "Epoch [31/300], d_loss: 1.1211, g_loss: 1.0816, D(x): 0.62, D(G(z)): 0.40\n",
            "Epoch [32/300], d_loss: 1.0054, g_loss: 1.2729, D(x): 0.64, D(G(z)): 0.34\n",
            "Epoch [33/300], d_loss: 1.0439, g_loss: 1.2274, D(x): 0.66, D(G(z)): 0.36\n",
            "Epoch [34/300], d_loss: 0.8992, g_loss: 1.2363, D(x): 0.69, D(G(z)): 0.33\n",
            "Epoch [35/300], d_loss: 0.9611, g_loss: 1.2374, D(x): 0.69, D(G(z)): 0.35\n",
            "Epoch [36/300], d_loss: 0.9333, g_loss: 1.2798, D(x): 0.76, D(G(z)): 0.40\n",
            "Epoch [37/300], d_loss: 1.2316, g_loss: 1.2652, D(x): 0.60, D(G(z)): 0.39\n",
            "Epoch [38/300], d_loss: 0.9484, g_loss: 1.1902, D(x): 0.66, D(G(z)): 0.35\n",
            "Epoch [39/300], d_loss: 0.9313, g_loss: 1.3283, D(x): 0.75, D(G(z)): 0.36\n",
            "Epoch [40/300], d_loss: 0.9533, g_loss: 1.3073, D(x): 0.68, D(G(z)): 0.33\n",
            "Epoch [41/300], d_loss: 1.0226, g_loss: 1.1532, D(x): 0.69, D(G(z)): 0.39\n",
            "Epoch [42/300], d_loss: 1.1519, g_loss: 1.2333, D(x): 0.58, D(G(z)): 0.35\n",
            "Epoch [43/300], d_loss: 1.1643, g_loss: 1.0916, D(x): 0.56, D(G(z)): 0.37\n",
            "Epoch [44/300], d_loss: 1.2462, g_loss: 1.0713, D(x): 0.54, D(G(z)): 0.38\n",
            "Epoch [45/300], d_loss: 1.0107, g_loss: 1.2291, D(x): 0.64, D(G(z)): 0.36\n",
            "Epoch [46/300], d_loss: 1.0567, g_loss: 1.3805, D(x): 0.65, D(G(z)): 0.32\n",
            "Epoch [47/300], d_loss: 1.0821, g_loss: 1.0602, D(x): 0.63, D(G(z)): 0.41\n",
            "Epoch [48/300], d_loss: 1.1541, g_loss: 1.2049, D(x): 0.60, D(G(z)): 0.37\n",
            "Epoch [49/300], d_loss: 1.0385, g_loss: 1.0781, D(x): 0.65, D(G(z)): 0.37\n",
            "Epoch [50/300], d_loss: 1.1551, g_loss: 0.9773, D(x): 0.59, D(G(z)): 0.40\n",
            "Epoch [51/300], d_loss: 1.0316, g_loss: 1.1371, D(x): 0.66, D(G(z)): 0.37\n",
            "Epoch [52/300], d_loss: 1.1690, g_loss: 0.9800, D(x): 0.61, D(G(z)): 0.41\n",
            "Epoch [53/300], d_loss: 1.1075, g_loss: 1.1263, D(x): 0.61, D(G(z)): 0.38\n",
            "Epoch [54/300], d_loss: 1.1552, g_loss: 1.0076, D(x): 0.60, D(G(z)): 0.39\n",
            "Epoch [55/300], d_loss: 1.0653, g_loss: 1.2047, D(x): 0.60, D(G(z)): 0.33\n",
            "Epoch [56/300], d_loss: 1.1143, g_loss: 0.9511, D(x): 0.61, D(G(z)): 0.39\n",
            "Epoch [57/300], d_loss: 1.1744, g_loss: 1.1992, D(x): 0.61, D(G(z)): 0.37\n",
            "Epoch [58/300], d_loss: 1.1191, g_loss: 1.0521, D(x): 0.60, D(G(z)): 0.39\n",
            "Epoch [59/300], d_loss: 1.2678, g_loss: 0.9107, D(x): 0.53, D(G(z)): 0.41\n",
            "Epoch [60/300], d_loss: 1.0993, g_loss: 1.0550, D(x): 0.62, D(G(z)): 0.39\n",
            "Epoch [61/300], d_loss: 1.2916, g_loss: 0.9875, D(x): 0.56, D(G(z)): 0.41\n",
            "Epoch [62/300], d_loss: 1.2960, g_loss: 1.0361, D(x): 0.53, D(G(z)): 0.39\n",
            "Epoch [63/300], d_loss: 1.1631, g_loss: 1.0863, D(x): 0.64, D(G(z)): 0.40\n",
            "Epoch [64/300], d_loss: 1.1451, g_loss: 1.1203, D(x): 0.61, D(G(z)): 0.36\n",
            "Epoch [65/300], d_loss: 1.0142, g_loss: 1.0354, D(x): 0.71, D(G(z)): 0.42\n",
            "Epoch [66/300], d_loss: 1.2513, g_loss: 1.0020, D(x): 0.56, D(G(z)): 0.42\n",
            "Epoch [67/300], d_loss: 1.1600, g_loss: 1.0590, D(x): 0.64, D(G(z)): 0.40\n",
            "Epoch [68/300], d_loss: 1.1390, g_loss: 1.0531, D(x): 0.63, D(G(z)): 0.42\n",
            "Epoch [69/300], d_loss: 1.2467, g_loss: 1.0510, D(x): 0.61, D(G(z)): 0.43\n",
            "Epoch [70/300], d_loss: 1.2178, g_loss: 1.0742, D(x): 0.57, D(G(z)): 0.41\n",
            "Epoch [71/300], d_loss: 1.1235, g_loss: 1.0437, D(x): 0.62, D(G(z)): 0.41\n",
            "Epoch [72/300], d_loss: 1.2717, g_loss: 1.0232, D(x): 0.63, D(G(z)): 0.44\n",
            "Epoch [73/300], d_loss: 1.1143, g_loss: 1.2114, D(x): 0.61, D(G(z)): 0.35\n",
            "Epoch [74/300], d_loss: 1.3849, g_loss: 1.0371, D(x): 0.51, D(G(z)): 0.40\n",
            "Epoch [75/300], d_loss: 1.2652, g_loss: 0.9668, D(x): 0.57, D(G(z)): 0.41\n",
            "Epoch [76/300], d_loss: 1.2936, g_loss: 0.9327, D(x): 0.54, D(G(z)): 0.44\n",
            "Epoch [77/300], d_loss: 1.2128, g_loss: 0.8957, D(x): 0.60, D(G(z)): 0.44\n",
            "Epoch [78/300], d_loss: 1.2470, g_loss: 0.9348, D(x): 0.55, D(G(z)): 0.41\n",
            "Epoch [79/300], d_loss: 1.4245, g_loss: 1.1589, D(x): 0.58, D(G(z)): 0.41\n",
            "Epoch [80/300], d_loss: 1.0579, g_loss: 0.9698, D(x): 0.64, D(G(z)): 0.41\n",
            "Epoch [81/300], d_loss: 1.2355, g_loss: 0.8670, D(x): 0.58, D(G(z)): 0.42\n",
            "Epoch [82/300], d_loss: 1.1465, g_loss: 1.0617, D(x): 0.59, D(G(z)): 0.37\n",
            "Epoch [83/300], d_loss: 1.2827, g_loss: 1.2092, D(x): 0.55, D(G(z)): 0.38\n",
            "Epoch [84/300], d_loss: 1.0205, g_loss: 1.0471, D(x): 0.63, D(G(z)): 0.35\n",
            "Epoch [85/300], d_loss: 0.9998, g_loss: 1.1758, D(x): 0.67, D(G(z)): 0.37\n",
            "Epoch [86/300], d_loss: 1.2868, g_loss: 0.9617, D(x): 0.62, D(G(z)): 0.46\n",
            "Epoch [87/300], d_loss: 1.1515, g_loss: 0.9681, D(x): 0.59, D(G(z)): 0.40\n",
            "Epoch [88/300], d_loss: 1.1416, g_loss: 0.9988, D(x): 0.63, D(G(z)): 0.42\n",
            "Epoch [89/300], d_loss: 1.2019, g_loss: 1.0914, D(x): 0.62, D(G(z)): 0.40\n",
            "Epoch [90/300], d_loss: 1.0406, g_loss: 1.1378, D(x): 0.72, D(G(z)): 0.41\n",
            "Epoch [91/300], d_loss: 1.3473, g_loss: 1.0796, D(x): 0.56, D(G(z)): 0.43\n",
            "Epoch [92/300], d_loss: 1.1347, g_loss: 1.1091, D(x): 0.61, D(G(z)): 0.38\n",
            "Epoch [93/300], d_loss: 1.1831, g_loss: 0.9537, D(x): 0.58, D(G(z)): 0.42\n",
            "Epoch [94/300], d_loss: 1.2936, g_loss: 1.2759, D(x): 0.63, D(G(z)): 0.39\n",
            "Epoch [95/300], d_loss: 1.1113, g_loss: 1.1552, D(x): 0.62, D(G(z)): 0.38\n",
            "Epoch [96/300], d_loss: 1.2933, g_loss: 1.1436, D(x): 0.53, D(G(z)): 0.37\n",
            "Epoch [97/300], d_loss: 1.1859, g_loss: 1.0492, D(x): 0.60, D(G(z)): 0.40\n",
            "Epoch [98/300], d_loss: 1.3589, g_loss: 0.8676, D(x): 0.52, D(G(z)): 0.44\n",
            "Epoch [99/300], d_loss: 1.0749, g_loss: 1.0347, D(x): 0.65, D(G(z)): 0.41\n",
            "Epoch [100/300], d_loss: 1.1546, g_loss: 1.0293, D(x): 0.68, D(G(z)): 0.43\n",
            "Epoch [101/300], d_loss: 1.3195, g_loss: 0.8647, D(x): 0.55, D(G(z)): 0.46\n",
            "Epoch [102/300], d_loss: 1.2574, g_loss: 0.8515, D(x): 0.56, D(G(z)): 0.45\n",
            "Epoch [103/300], d_loss: 1.3037, g_loss: 0.9858, D(x): 0.60, D(G(z)): 0.45\n",
            "Epoch [104/300], d_loss: 1.2014, g_loss: 1.0028, D(x): 0.61, D(G(z)): 0.42\n",
            "Epoch [105/300], d_loss: 1.2138, g_loss: 0.9305, D(x): 0.58, D(G(z)): 0.44\n",
            "Epoch [106/300], d_loss: 1.3033, g_loss: 1.0783, D(x): 0.55, D(G(z)): 0.41\n",
            "Epoch [107/300], d_loss: 1.2699, g_loss: 1.1111, D(x): 0.66, D(G(z)): 0.43\n",
            "Epoch [108/300], d_loss: 1.0624, g_loss: 1.1576, D(x): 0.64, D(G(z)): 0.37\n",
            "Epoch [109/300], d_loss: 1.2288, g_loss: 1.0384, D(x): 0.58, D(G(z)): 0.41\n",
            "Epoch [110/300], d_loss: 1.2341, g_loss: 1.0929, D(x): 0.60, D(G(z)): 0.42\n",
            "Epoch [111/300], d_loss: 1.2459, g_loss: 1.0428, D(x): 0.55, D(G(z)): 0.39\n",
            "Epoch [112/300], d_loss: 1.2532, g_loss: 0.9976, D(x): 0.58, D(G(z)): 0.41\n",
            "Epoch [113/300], d_loss: 1.1200, g_loss: 1.0204, D(x): 0.63, D(G(z)): 0.40\n",
            "Epoch [114/300], d_loss: 1.2924, g_loss: 0.9028, D(x): 0.57, D(G(z)): 0.45\n",
            "Epoch [115/300], d_loss: 1.1258, g_loss: 0.9719, D(x): 0.60, D(G(z)): 0.41\n",
            "Epoch [116/300], d_loss: 1.1599, g_loss: 1.1225, D(x): 0.63, D(G(z)): 0.41\n",
            "Epoch [117/300], d_loss: 1.1554, g_loss: 1.0830, D(x): 0.58, D(G(z)): 0.39\n",
            "Epoch [118/300], d_loss: 1.1585, g_loss: 0.9593, D(x): 0.61, D(G(z)): 0.42\n",
            "Epoch [119/300], d_loss: 1.4374, g_loss: 1.1495, D(x): 0.55, D(G(z)): 0.43\n",
            "Epoch [120/300], d_loss: 1.1453, g_loss: 1.0710, D(x): 0.60, D(G(z)): 0.39\n",
            "Epoch [121/300], d_loss: 1.3239, g_loss: 0.9321, D(x): 0.56, D(G(z)): 0.43\n",
            "Epoch [122/300], d_loss: 1.1748, g_loss: 0.9852, D(x): 0.59, D(G(z)): 0.42\n",
            "Epoch [123/300], d_loss: 1.2828, g_loss: 0.9038, D(x): 0.55, D(G(z)): 0.44\n",
            "Epoch [124/300], d_loss: 1.2627, g_loss: 0.9025, D(x): 0.61, D(G(z)): 0.45\n",
            "Epoch [125/300], d_loss: 1.2154, g_loss: 0.9003, D(x): 0.56, D(G(z)): 0.44\n",
            "Epoch [126/300], d_loss: 1.1595, g_loss: 1.0246, D(x): 0.57, D(G(z)): 0.38\n",
            "Epoch [127/300], d_loss: 1.4581, g_loss: 0.8596, D(x): 0.55, D(G(z)): 0.49\n",
            "Epoch [128/300], d_loss: 1.1811, g_loss: 0.8579, D(x): 0.58, D(G(z)): 0.44\n",
            "Epoch [129/300], d_loss: 1.2516, g_loss: 1.1964, D(x): 0.57, D(G(z)): 0.38\n",
            "Epoch [130/300], d_loss: 1.2807, g_loss: 1.0455, D(x): 0.59, D(G(z)): 0.41\n",
            "Epoch [131/300], d_loss: 1.2770, g_loss: 0.8786, D(x): 0.57, D(G(z)): 0.44\n",
            "Epoch [132/300], d_loss: 1.4230, g_loss: 1.0660, D(x): 0.53, D(G(z)): 0.43\n",
            "Epoch [133/300], d_loss: 1.2145, g_loss: 0.9482, D(x): 0.59, D(G(z)): 0.43\n",
            "Epoch [134/300], d_loss: 1.2055, g_loss: 1.0306, D(x): 0.64, D(G(z)): 0.43\n",
            "Epoch [135/300], d_loss: 1.1734, g_loss: 1.0466, D(x): 0.59, D(G(z)): 0.37\n",
            "Epoch [136/300], d_loss: 1.1648, g_loss: 0.9465, D(x): 0.60, D(G(z)): 0.44\n",
            "Epoch [137/300], d_loss: 1.2570, g_loss: 0.9696, D(x): 0.59, D(G(z)): 0.44\n",
            "Epoch [138/300], d_loss: 1.2861, g_loss: 0.8851, D(x): 0.57, D(G(z)): 0.46\n",
            "Epoch [139/300], d_loss: 1.2306, g_loss: 1.1157, D(x): 0.51, D(G(z)): 0.35\n",
            "Epoch [140/300], d_loss: 1.3064, g_loss: 0.9193, D(x): 0.56, D(G(z)): 0.47\n",
            "Epoch [141/300], d_loss: 1.1605, g_loss: 1.0176, D(x): 0.61, D(G(z)): 0.43\n",
            "Epoch [142/300], d_loss: 1.2182, g_loss: 1.0756, D(x): 0.62, D(G(z)): 0.41\n",
            "Epoch [143/300], d_loss: 1.2388, g_loss: 0.9752, D(x): 0.55, D(G(z)): 0.40\n",
            "Epoch [144/300], d_loss: 1.2683, g_loss: 0.7933, D(x): 0.56, D(G(z)): 0.47\n",
            "Epoch [145/300], d_loss: 1.1974, g_loss: 1.0251, D(x): 0.59, D(G(z)): 0.41\n",
            "Epoch [146/300], d_loss: 1.2980, g_loss: 0.9369, D(x): 0.50, D(G(z)): 0.42\n",
            "Epoch [147/300], d_loss: 1.2298, g_loss: 0.9230, D(x): 0.54, D(G(z)): 0.43\n",
            "Epoch [148/300], d_loss: 1.2977, g_loss: 1.0026, D(x): 0.56, D(G(z)): 0.45\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b0600022b2c2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# 판별자가 진짜 이미지를 진짜로 인식하는 오차 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 판별자가 진짜 이미지 + 라벨값을 0~1으로 진짜/가짜 여부를 판단\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# BCELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mreal_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;31m# 판별자 vs 진짜 이미지\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-8f95f1c789f7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, labels)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 진짜인지 가짜인지 (0, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mleaky_relu\u001b[0;34m(input, negative_slope, inplace)\u001b[0m\n\u001b[1;32m   1628\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1631\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_slope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES = {\n",
        "    0: 'T-shirt/top',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'Ankle boot'\n",
        "}"
      ],
      "metadata": {
        "id": "TFuEL5nUdtDw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/BigData23th/Data/raw/main/d2.pt\n",
        "!wget https://github.com/BigData23th/Data/raw/main/g2.pt"
      ],
      "metadata": {
        "id": "oFYU6xWOd54E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6151f0b0-7fad-4af3-e25f-0ef1672e3841"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-04 08:31:11--  https://github.com/BigData23th/Data/raw/main/d2.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BigData23th/Data/main/d2.pt [following]\n",
            "--2023-04-04 08:31:12--  https://raw.githubusercontent.com/BigData23th/Data/main/d2.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5884948 (5.6M) [application/octet-stream]\n",
            "Saving to: ‘d2.pt’\n",
            "\n",
            "d2.pt               100%[===================>]   5.61M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-04-04 08:31:13 (337 MB/s) - ‘d2.pt’ saved [5884948/5884948]\n",
            "\n",
            "--2023-04-04 08:31:13--  https://github.com/BigData23th/Data/raw/main/g2.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/BigData23th/Data/main/g2.pt [following]\n",
            "--2023-04-04 08:31:13--  https://raw.githubusercontent.com/BigData23th/Data/main/g2.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5958676 (5.7M) [application/octet-stream]\n",
            "Saving to: ‘g2.pt’\n",
            "\n",
            "g2.pt               100%[===================>]   5.68M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-04-04 08:31:14 (321 MB/s) - ‘g2.pt’ saved [5958676/5958676]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D.load_state_dict(torch.load('d2.pt'))\n",
        "G.load_state_dict(torch.load('g2.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8c2b5F5eDXr",
        "outputId": "a648ac6a-61c1-4e74-a36f-6c5948bc77a3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 만들고 싶은 아이템 생성하고 시각화하기\n",
        "# 아이템 번호\n",
        "item_number = 9 #@param {\"type\":\"number\"}\n",
        "z = torch.randn(1, 100).to(DEVICE) # 배치 크기 1\n",
        "g_label = torch.full((1,), item_number, dtype=torch.long).to(DEVICE)\n",
        "sample_images = G(z, g_label) # 텐서\n",
        "# CPU, Numpy -> Matplotlib\n",
        "sample_images_img = np.reshape(sample_images.data.cpu().numpy()\n",
        "                               [0],(28, 28)) # 784\n",
        "plt.title(CLASSES[item_number])\n",
        "plt.imshow(sample_images_img, cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "cellView": "form",
        "id": "NN6IZHU6eIxD",
        "outputId": "d85bd150-1ecc-4ebf-82c7-63fa7a87bc67"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> PyTorch를 통해서 GAN 모델을 사용한다고 했을 때, 가장 최신 GAN 모델은 뭐야? + BingGPT\n",
        "* https://shareg.pt/3lWApU7"
      ],
      "metadata": {
        "id": "ODu3jO3MMu_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> https://www.kaggle.com/search?q=dcgan+pytorch+sortBy%3Adate"
      ],
      "metadata": {
        "id": "tvVSkT-vM050"
      }
    }
  ]
}